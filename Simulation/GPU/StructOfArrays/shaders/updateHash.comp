#version 460

#define WORK_GROUP_SIZE 25

layout (local_size_x = WORK_GROUP_SIZE) in;

#define PARTICLE_RADIUS 0.005f

uniform int Number_Particles;
uniform mat4 m_model;

uniform float MASS;
uniform float RESTDENSITY;
uniform int HASHSIZE;
uniform int PONTOS_LADO;
uniform float H;

layout(std430, binding = 0) buffer Position
{
    vec4 position[];
};

layout(std430, binding = 1) buffer Velocity
{
    vec4 velocity[];
};



layout(std430, binding = 2) buffer TempPosition
{
    vec4 tempPosition[];
};

layout(std430, binding = 3) buffer BucketSizes
{
    int bucketSizes[];
};



layout(std430, binding = 4) buffer TempVelocity
{
    vec4 tempvelocity[];
};

layout(std430, binding = 5) buffer TempBucketSizes
{
    int tempBucketSizes[];
};


float rand(vec2 co){
    return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
}

uint hashFunction(vec4 pos,double H,int size) {
    
    int p1 = 2693;
    int p2 = 3163;
    int p3 = 4091;

    int part1 = (int((pos.x / H)) * p1);
    int part2 = (int((pos.y / H)) * p2);
    int part3 = (int ((pos.z / H)) * p3);
    
    uint ret = uint((part1 ^ part2 ^ part3) % size);
    
    return ret;
}

void main()
{
    
    
    uint index = gl_GlobalInvocationID.x;

    if (index > Number_Particles)
        return;

    //Agora vai correr todas as particulas de novo e vai adicionar ao hashmap
    // e no final vai hazer o compute dos offsets
    

    uint bucket = hashFunction(tempPosition[index], H, HASHSIZE);
    int bucketSize= atomicAdd(bucketSizes[bucket],1);
    int offset = 0;
    //vai correr o array com os tamanhos dos buckets até chegar ao bucket atual
    for (int j = 0; j < bucket; j++)
    {
        //exemplo, se tivermos um array com [p1,p2,p3,p4]
        //p1 e p2 sao do bucket 0 e p3 e p4 do bucket 1
        //o bucket 1 começa no indice 2 que é o bucketsize do bucket 0
        offset += tempBucketSizes[j];
    }

    position[offset+bucketSize] = tempPosition[index];
    velocity[offset+bucketSize] = tempvelocity[index];
        

    


}